#!/usr/bin/env python3
"""
æ¡¥æ¢æœåŠ¡ (Bridge Server) - æŒä¹…åŒ–ä¼šè¯æœ€ç»ˆç‰ˆ
- å¯¹æ¥ Streamlit å‰ç«¯ (æä¾› SSE æµå¼ HTTP æ¥å£)
- å¯¹æ¥ ç ”ç©¶åç«¯ (ç®¡ç†æŒä¹…åŒ–çš„ WebSocket å®¢æˆ·ç«¯è¿æ¥)
- [æ ¸å¿ƒæ”¹é€ ] ä¸ºæ¯ä¸ª job_id/client_id ç»´æŠ¤ä¸€ä¸ªé•¿æœŸå­˜æ´»çš„ WebSocket è¿æ¥ï¼ŒçœŸæ­£å®ç°æœ‰çŠ¶æ€çš„å¤šè½®å¯¹è¯ã€‚
- [æ–°] å¢åŠ äº†ä¼šè¯è¶…æ—¶è‡ªåŠ¨æ¸…ç†æœºåˆ¶ï¼Œé˜²æ­¢èµ„æºæ³„æ¼ã€‚
- å°†æ—¥å¿—åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œ bridge_server.log æ–‡ä»¶
"""
import asyncio
import json
import logging
import sys
import uuid
from typing import Dict, Any, List, Union
from datetime import datetime, timedelta

import websockets
from fastapi import FastAPI, Request
from fastapi.responses import StreamingResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware

# --- æ—¥å¿—é…ç½® ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('bridge_server.log', mode='w', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger('bridge_server')


# --- [å·²é‡æ„] WebSocket å®¢æˆ·ç«¯é€»è¾‘ (æ”¯æŒæŒä¹…åŒ–è¿æ¥) ---
class PersistentResearchClient:
    """
    ä¸ºæ¯ä¸ªä¼šè¯ï¼ˆjob_idï¼‰ç®¡ç†ä¸€ä¸ªåˆ°ç ”ç©¶åç«¯çš„æŒä¹… WebSocket è¿æ¥ã€‚
    """
    def __init__(self, client_id: str, host='localhost', port=30052):
        self.client_id = client_id
        self.ws_url = f"ws://{host}:{port}/ws/{self.client_id}"
        self.websocket: websockets.WebSocketClientProtocol = None
        self.connected = False
        # æ¯ä¸ªHTTPè¯·æ±‚éƒ½æœ‰è‡ªå·±çš„é˜Ÿåˆ—ï¼Œä»¥æ¥æ”¶æ¥è‡ªå…±äº«WebSocketçš„å“åº”
        self.response_queues: List[asyncio.Queue] = []
        self._lock = asyncio.Lock()
        self._listener_task: asyncio.Task = None
        self.last_activity = datetime.utcnow()

    async def connect(self):
        """å»ºç«‹å¹¶ç»´æŒä¸€ä¸ªåˆ°ç ”ç©¶åç«¯çš„WebSocketè¿æ¥ï¼Œå¹¶å¯åŠ¨ç›‘å¬å™¨ã€‚"""
        if self.connected:
            return
        try:
            # è®¾ç½®æ›´é•¿çš„ ping è¶…æ—¶ä»¥ä¿æŒè¿æ¥
            self.websocket = await websockets.connect(self.ws_url, open_timeout=10, ping_interval=20, ping_timeout=60)
            self.connected = True
            self._listener_task = asyncio.create_task(self._listen_for_messages())
            logger.info(f"ğŸ”Œ [{self.client_id}] æŒä¹…åŒ– WebSocket å·²è¿æ¥: {self.ws_url}")
        except Exception as e:
            logger.error(f"âŒ [{self.client_id}] WebSocket è¿æ¥å¤±è´¥: {e}")
            self.connected = False
            await self._broadcast_error(f"æ— æ³•è¿æ¥åˆ°ç ”ç©¶åç«¯: {e}")

    async def _listen_for_messages(self):
        """[æ ¸å¿ƒ] é•¿æœŸè¿è¡Œçš„ä»»åŠ¡ï¼ŒæŒç»­ä» WebSocket æ¥æ”¶æ¶ˆæ¯å¹¶åˆ†å‘åˆ°æ‰€æœ‰ç­‰å¾…çš„è¯·æ±‚é˜Ÿåˆ—ä¸­ã€‚"""
        try:
            while self.connected:
                try:
                    message_data = await self.websocket.recv()
                    message = json.loads(message_data)
                    logger.info(f"ğŸ“¨ [{self.client_id}] ä»åç«¯æ”¶åˆ°æ¶ˆæ¯: {message_data[:300]}")
                    self.last_activity = datetime.utcnow()
                    await self._broadcast(message)
                    # å¦‚æœæ˜¯æœ€ç»ˆå“åº”ï¼Œåˆ™æ ‡è®°æœ¬æ¬¡äº¤äº’å®Œæˆ
                    if message.get('type') == 'research_response':
                         await self._broadcast({"type": "done_interaction"})
                except websockets.exceptions.ConnectionClosed as e:
                    logger.warning(f"ğŸ”Œ [{self.client_id}] åç«¯ WebSocket è¿æ¥å·²å…³é—­: {e}")
                    await self._broadcast_error("ä¸ç ”ç©¶åç«¯çš„è¿æ¥å·²æ„å¤–å…³é—­ã€‚")
                    break
        except Exception as e:
            logger.error(f"âŒ [{self.client_id}] ç›‘å¬ä»»åŠ¡å¼‚å¸¸: {e}", exc_info=True)
            await self._broadcast_error(f"å¤„ç†æ¶ˆæ¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        finally:
            self.connected = False

    async def send_message(self, message: Dict[str, Any]) -> asyncio.Queue:
        """å‘é€æ¶ˆæ¯åˆ°ç ”ç©¶åç«¯ï¼Œå¹¶è¿”å›ä¸€ä¸ªé˜Ÿåˆ—ä»¥æ¥æ”¶æœ¬æ¬¡è¯·æ±‚çš„å“åº”ã€‚"""
        async with self._lock:
            if not self.connected:
                await self.connect()

            if not self.connected:
                 # å¦‚æœè¿æ¥å¤±è´¥ï¼Œè¿”å›ä¸€ä¸ªå·²ç»åŒ…å«é”™è¯¯çš„é˜Ÿåˆ—
                error_queue = asyncio.Queue()
                await error_queue.put({"type": "error", "message": "æ— æ³•ä¸ç ”ç©¶åç«¯å»ºç«‹è¿æ¥ã€‚"})
                return error_queue

            # ä¸ºè¿™ä¸ªç‰¹å®šçš„HTTPè¯·æ±‚åˆ›å»ºä¸€ä¸ªæ–°çš„å“åº”é˜Ÿåˆ—
            queue = asyncio.Queue()
            self.response_queues.append(queue)
            
            try:
                await self.websocket.send(json.dumps(message, ensure_ascii=False))
                self.last_activity = datetime.utcnow()
                logger.info(f"ğŸ“¤ [{self.client_id}] å‘é€åˆ°ç ”ç©¶åç«¯: {json.dumps(message, ensure_ascii=False)}")
            except Exception as e:
                logger.error(f"âŒ [{self.client_id}] å‘é€æ¶ˆæ¯å¤±è´¥: {e}")
                await queue.put({"type": "error", "message": f"å‘é€æ¶ˆæ¯å¤±è´¥: {e}"})

            return queue

    def remove_queue(self, queue: asyncio.Queue):
        """å½“ä¸€ä¸ªHTTPè¯·æ±‚ç»“æŸåï¼Œç§»é™¤å…¶å¯¹åº”çš„å“åº”é˜Ÿåˆ—ã€‚"""
        if queue in self.response_queues:
            self.response_queues.remove(queue)

    async def _broadcast(self, message: Dict[str, Any]):
        """å°†ä»WebSocketæ”¶åˆ°çš„æ¶ˆæ¯æ”¾å…¥æ‰€æœ‰å½“å‰æ´»åŠ¨çš„è¯·æ±‚é˜Ÿåˆ—ä¸­ã€‚"""
        for queue in self.response_queues:
            await queue.put(message)

    async def _broadcast_error(self, error_message: str):
        """å¹¿æ’­é”™è¯¯ä¿¡æ¯å¹¶ç»“æŸæ‰€æœ‰ç­‰å¾…çš„è¯·æ±‚ã€‚"""
        error_payload = {"type": "error", "message": error_message}
        await self._broadcast(error_payload)
        await self._broadcast({"type": "done_interaction"})


    async def disconnect(self):
        """å®‰å…¨åœ°æ–­å¼€WebSocketè¿æ¥å¹¶åœæ­¢ç›‘å¬ä»»åŠ¡ã€‚"""
        if self.connected and self.websocket:
            self.connected = False
            await self.websocket.close()
        if self._listener_task and not self._listener_task.done():
            self._listener_task.cancel()
        logger.info(f"ğŸ”Œ [{self.client_id}] æŒä¹…åŒ– WebSocket å·²æ–­å¼€ã€‚")

# --- FastAPI åº”ç”¨å®šä¹‰ ---
app = FastAPI(title="Streamlit Bridge Service")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])

# [æ ¸å¿ƒ] å…¨å±€ä¼šè¯ç®¡ç†å™¨ï¼Œå­˜å‚¨æŒä¹…åŒ–çš„å®¢æˆ·ç«¯å®ä¾‹
client_sessions: Dict[str, PersistentResearchClient] = {}
SESSION_TIMEOUT = timedelta(minutes=30) # 30åˆ†é’Ÿæ— æ´»åŠ¨åˆ™æ¸…ç†ä¼šè¯

def format_sse_from_backend_response(backend_response: Dict[str, Any]) -> Union[Dict, List[Dict], None]:
    """å°†ä»ç ”ç©¶åç«¯æ”¶åˆ°çš„ã€ä»»ä½•ã€‘å“åº”æ ¼å¼åŒ–ä¸ºå‰ç«¯æœŸæœ›çš„ä¸€ä¸ªæˆ–å¤šä¸ªSSEäº‹ä»¶"""
    response_type = backend_response.get("type")
    
    if response_type == 'research_event':
        data = backend_response.get("data", {})
        state = data.get("current_state", "çŠ¶æ€æ›´æ–°")
        
        if "search_queries" in data and data.get("search_queries"):
            # ä¸“ç”¨äºæœç´¢æ—¥å¿—
            return {"type": "search_log", "state": state, "queries": data["search_queries"]}
        else:
            # â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
            # â˜…â˜…â˜…               æ ¸å¿ƒä¿®å¤ï¼šä¼ é€’ web_pages æ•°æ®              â˜…â˜…â˜…
            # â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
            # é»˜è®¤ä¸ºçŠ¶æ€æ›´æ–°äº‹ä»¶
            sse_event = {
                "type": "state_update",
                "state": state,
                "message": data.get("current_message", "")
            }
            # å¦‚æœåŸå§‹æ•°æ®ä¸­å­˜åœ¨ web_pagesï¼Œå°†å…¶æ·»åŠ åˆ°è¦å‘å¾€å‰ç«¯çš„äº‹ä»¶ä¸­
            if "web_pages" in data and data.get("web_pages"):
                sse_event["web_pages"] = data["web_pages"]
            return sse_event
    
    if response_type == 'research_response':
        status = backend_response.get("status")
        if status == "success":
            report = backend_response.get("final_report", "")
            return [{"type": "final_report_chunk", "content": report[i:i+20]} for i in range(0, len(report), 20)] if report else []
        elif status == "clarification_needed":
            data = backend_response.get("data", {})
            return {"type": "clarification_needed", "message": data.get("current_message", "è¯·æä¾›æ›´å¤šä¿¡æ¯ã€‚")}
        elif status == "error":
            return {"type": "error", "message": backend_response.get("error") or backend_response.get("message", "åç«¯è¿”å›æœªçŸ¥é”™è¯¯ã€‚")}
    
    if response_type == "error":
        return backend_response
        
    return None


@app.post("/research")
async def research_endpoint(request: Request):
    try:
        payload = await request.json()
    except json.JSONDecodeError:
        return JSONResponse(status_code=400, content={"type": "error", "message": "æ— æ•ˆçš„JSONè¯·æ±‚ä½“"})
        
    logger.info(f"æ”¶åˆ°å‰ç«¯è¯·æ±‚: {payload}")
    job_id = payload.get("job_id")
    if not job_id:
        return JSONResponse(status_code=400, content={"type": "error", "message": "è¯·æ±‚ä¸­ç¼ºå°‘ job_id"})

    client = client_sessions.get(job_id)
    if not client:
        logger.info(f"âœ¨ ä¸º job_id '{job_id}' åˆ›å»ºæ–°çš„æŒä¹…åŒ–ä¼šè¯å®ä¾‹")
        client = PersistentResearchClient(client_id=job_id)
        client_sessions[job_id] = client

    clarification_history = payload.get("clarification_history", [])
    if len(clarification_history) <= 1:
        backend_message = {'type': 'start_research', 'question': payload.get("query")}
    else:
        backend_message = {'type': 'continue_research', 'clarification': payload.get("clarification")}
    
    response_queue = await client.send_message(backend_message)

    async def stream_generator():
        try:
            while True:
                backend_response = await response_queue.get()
                
                if backend_response.get("type") == "done_interaction":
                    break
                
                sse_events = format_sse_from_backend_response(backend_response)
                if sse_events:
                    if not isinstance(sse_events, list): sse_events = [sse_events]
                    for event in sse_events:
                        yield f"data: {json.dumps(event, ensure_ascii=False)}\n\n"
                        if event.get("type") == "final_report_chunk": await asyncio.sleep(0.02)
        
        except asyncio.CancelledError:
            logger.warning(f"Frontend for job {job_id} disconnected. Cleaning up.")
            if job_id in client_sessions:
                await client_sessions[job_id].disconnect()
                del client_sessions[job_id]
                logger.info(f"âœ… ä¼šè¯ {job_id} å·²å› å‰ç«¯æ–­å¼€è€Œæ¸…ç†ã€‚")
        finally:
            client.remove_queue(response_queue)

    return StreamingResponse(stream_generator(), media_type="text/event-stream")

async def cleanup_inactive_sessions():
    """å®šæœŸæ¸…ç†ä¸æ´»è·ƒçš„ä¼šè¯ä»¥é‡Šæ”¾èµ„æºã€‚"""
    while True:
        await asyncio.sleep(60)
        now = datetime.utcnow()
        inactive_sessions = []
        for job_id, client in client_sessions.items():
            if now - client.last_activity > SESSION_TIMEOUT:
                inactive_sessions.append(job_id)
        
        for job_id in inactive_sessions:
            logger.info(f"âŒ› ä¼šè¯ {job_id} å› é•¿æ—¶é—´ä¸æ´»è·ƒè€Œè¢«æ¸…ç†ã€‚")
            client = client_sessions.pop(job_id, None)
            if client:
                await client.disconnect()

@app.on_event("startup")
async def startup_event():
    asyncio.create_task(cleanup_inactive_sessions())

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8008)